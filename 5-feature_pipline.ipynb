{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.component.data_info import *\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date=Timestamp('2025-03-08 15:00:00+0000', tz='UTC')\n",
      "2025-03-08 15:00:00+00:00 2024-12-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hadeel\\AppData\\Local\\Temp\\ipykernel_28716\\3240295609.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  current_date = pd.to_datetime(datetime.utcnow(),utc=True).floor('h')\n"
     ]
    }
   ],
   "source": [
    "# specify the date we want to fetch our data\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "#specify the current time\n",
    "current_date = pd.to_datetime(datetime.utcnow(),utc=True).floor('h')\n",
    "print(f'{current_date=}')\n",
    "\n",
    "# we fetch raw data for the last 28 days, to add redundancy to our data pipeline\n",
    "fetch_data_to = current_date\n",
    "fetch_data_from = current_date - timedelta(days=90)#it should only fetch for the last hour but because we dont want the pipline to break in case this data or the provois our was not availble so thats why we added for the entier month\n",
    "fetch_data_from = pd.Timestamp(year=fetch_data_from.year, month=fetch_data_from.month, day=1,tz='UTC')\n",
    "print(fetch_data_to, fetch_data_from )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch batch of data from the wherehous\n",
    "\n",
    "def fetch_batch_raw_data(from_date: datetime, to_date: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate production data by sampling historical data from 52 weeks ago (i.e. 1 year)\n",
    "    \"\"\"\n",
    "    from_date_ = from_date - timedelta(days=7*52)\n",
    "    to_date_ = to_date - timedelta(days=7*52)\n",
    "    print(f'{from_date=}, {to_date_=}')\n",
    "\n",
    "    # download 2 files from website\n",
    "    demand_values = load_full_data(from_date_,to_date_)\n",
    "    demand_values = demand_values[(demand_values.date >= from_date_) & (demand_values.date <= to_date_)]\n",
    "\n",
    "\n",
    "    # shift the data to pretend this is recent data\n",
    "    demand_values['date'] += timedelta(days=7*52)\n",
    "\n",
    "    demand_values.sort_values(by=['sub_region_code', 'date'], inplace=True)\n",
    "\n",
    "    return demand_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_date=Timestamp('2024-12-01 00:00:00+0000', tz='UTC'), to_date_=Timestamp('2024-03-09 15:00:00+0000', tz='UTC')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_full_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mfetch_batch_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetch_data_from\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfetch_data_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m, in \u001b[0;36mfetch_batch_raw_data\u001b[1;34m(from_date, to_date)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfrom_date\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_date_\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# download 2 files from website\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m demand_values \u001b[38;5;241m=\u001b[39m \u001b[43mload_full_data\u001b[49m(from_date_,to_date_)\n\u001b[0;32m     13\u001b[0m demand_values \u001b[38;5;241m=\u001b[39m demand_values[(demand_values\u001b[38;5;241m.\u001b[39mdate \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m from_date_) \u001b[38;5;241m&\u001b[39m (demand_values\u001b[38;5;241m.\u001b[39mdate \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m to_date_)]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# shift the data to pretend this is recent data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_full_data' is not defined"
     ]
    }
   ],
   "source": [
    "data=fetch_batch_raw_data(fetch_data_from,fetch_data_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to datetime\n",
    "data['date'] = pd.to_datetime(data['date'], utc=True)\n",
    "\n",
    "# add column with Unix epoch milliseconds\n",
    "data['seconds'] = data['date'].astype('int64') // 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               0\n",
       "sub_region_code    0\n",
       "demand             0\n",
       "temperature_2m     0\n",
       "seconds            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sub_region_code</th>\n",
       "      <th>demand</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26234</th>\n",
       "      <td>2025-02-04 10:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>1919</td>\n",
       "      <td>9.5085</td>\n",
       "      <td>1738663200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26223</th>\n",
       "      <td>2025-02-04 11:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2047</td>\n",
       "      <td>10.2585</td>\n",
       "      <td>1738666800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26212</th>\n",
       "      <td>2025-02-04 12:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2247</td>\n",
       "      <td>10.3585</td>\n",
       "      <td>1738670400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26201</th>\n",
       "      <td>2025-02-04 13:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2338</td>\n",
       "      <td>10.3585</td>\n",
       "      <td>1738674000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26190</th>\n",
       "      <td>2025-02-04 14:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2243</td>\n",
       "      <td>10.3585</td>\n",
       "      <td>1738677600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  sub_region_code demand  temperature_2m  \\\n",
       "26234 2025-02-04 10:00:00+00:00               10   1919          9.5085   \n",
       "26223 2025-02-04 11:00:00+00:00               10   2047         10.2585   \n",
       "26212 2025-02-04 12:00:00+00:00               10   2247         10.3585   \n",
       "26201 2025-02-04 13:00:00+00:00               10   2338         10.3585   \n",
       "26190 2025-02-04 14:00:00+00:00               10   2243         10.3585   \n",
       "\n",
       "             seconds  \n",
       "26234  1738663200000  \n",
       "26223  1738666800000  \n",
       "26212  1738670400000  \n",
       "26201  1738674000000  \n",
       "26190  1738677600000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from src.component import feature_group_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopsworks.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project = hopsworks.login(\n",
    "#     project=feature_group_config.HOPSWORKS_PROJECT_NAME,\n",
    "#     api_key_value=feature_group_config.HOPSWORKS_API_KEY\n",
    "# )\n",
    "# feature_store = project.get_feature_store()\n",
    "\n",
    "# FEATURE_GROUP_NAME = 'electricity_demand_feature_group2'\n",
    "# FEATURE_GROUP_VERSION = 3\n",
    "\n",
    "# feature_group = feature_store.get_or_create_feature_group(\n",
    "#     name=FEATURE_GROUP_NAME,\n",
    "#     version=FEATURE_GROUP_VERSION,\n",
    "#     description=\"Time-series data at hourly frequency\",\n",
    "#     primary_key = ['sub_region_code', 'date'],\n",
    "#     event_time='date',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-04 14:15:01,290 INFO: Initializing external client\n",
      "2025-02-04 14:15:01,291 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-02-04 14:15:02,429 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1212591\n"
     ]
    }
   ],
   "source": [
    "#save predictions to the feature store\n",
    "from src.component.feature_store_api import get_feature_store\n",
    "import src.component.feature_group_config as config\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=3,\n",
    "    description=\"Time-series data at hourly frequency\",\n",
    "    primary_key = ['sub_region_code', 'date'],\n",
    "    event_time='date',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 26224/26224 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: electricity_demand_feature_group2_3_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1212591/jobs/named/electricity_demand_feature_group2_3_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('electricity_demand_feature_group2_3_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "feature_group.insert(data, write_options={\"wait_for_job\": False})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-o1faXYQI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
